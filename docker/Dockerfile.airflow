# Use the official Apache Airflow base image (version 3.1.2)
FROM apache/airflow:3.1.2-python3.10

# Set environment variables
ENV AIRFLOW_HOME=/opt/airflow
ENV DBT_VENV_PATH="${AIRFLOW_HOME}/dbt_venv"
ENV DBT_PROJECT_PATH="${AIRFLOW_HOME}/dags/dbt"
ENV PATH="${DBT_VENV_PATH}/bin:${PATH}"
ENV JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64

# Switch to root to install system packages
USER root

# Install Java, Python venv tools, build essentials, Rust for Polars
RUN apt-get update && \
    apt-get install -y openjdk-17-jdk ant procps python3-venv build-essential rustc cargo && \
    apt-get clean

# Upgrade pip, setuptools, wheel
RUN python3 -m pip install --upgrade pip setuptools wheel

# Switch back to airflow user
USER airflow

# Create virtual environment for dbt and install all dbt packages together
RUN python3 -m venv "${DBT_VENV_PATH}" && \
    . "${DBT_VENV_PATH}/bin/activate" && \
    pip install --no-cache-dir \
        dbt-core==1.6.0 \
        dbt-bigquery==1.6.0 \
        dbt-redshift==1.6.0 \
        dbt-spark==1.6.0 && \
    deactivate

# Install other Airflow provider packages and dependencies
COPY ./docker/requirements_airflow.txt .
RUN . "${DBT_VENV_PATH}/bin/activate" && \
    pip install --no-cache-dir -r requirements_airflow.txt && \
    deactivate

# Setup dbt profiles
RUN mkdir -p "${AIRFLOW_HOME}/.dbt"
COPY ./dags/dbt/profiles.yml "${AIRFLOW_HOME}/.dbt/profiles.yml"

# Copy dags
COPY --chown=airflow:root ./dags /opt/airflow/dags