x-airflow-common:
  &airflow-common
  image: Batching/airflow
  environment:
    &airflow-common-env
    AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_CONTAINER_NAME}/${POSTGRES_DB}
    AIRFLOW__DATABASE__LOAD_DEFAULT_CONNECTIONS: 'false'
    AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.basic_auth'
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__CORE__FERNET_KEY: 'UKMzEm3yIuFYEq1y3-2FxPNWSVwRASpahmQ9kQfEr8E='
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'true'
    AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
    AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: 'true'
    AIRFLOW__SCHEDULER__DAG_DIR_LIST_INTERVAL: 60
    AIRFLOW__CORE__ENABLE_REACT_UI: 'true'
    _AIRFLOW_DB_UPGRADE: 'true'
    _AIRFLOW_DB_MIGRATE: 'true'
    _AIRFLOW_WWW_USER_CREATE: 'true'
    _AIRFLOW_WWW_USER_USERNAME: 'airflow'
    _AIRFLOW_WWW_USER_PASSWORD: 'airflow'
    _PIP_ADDITIONAL_REQUIREMENTS: ${_PIP_ADDITIONAL_REQUIREMENTS:-}
    AIRFLOW_UID: 50000
    POSTGRES_USER: ${POSTGRES_USER}
    POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    POSTGRES_DB: ${POSTGRES_DB}
    POSTGRES_CONTAINER_NAME: ${POSTGRES_CONTAINER_NAME}
    POSTGRES_PORT: ${POSTGRES_PORT}
    SPARK_MASTER_HOST_NAME: ${SPARK_MASTER_HOST_NAME}
    SPARK_MASTER_PORT: ${SPARK_MASTER_PORT}
  user: "${AIRFLOW_UID:-50000}:0"
  volumes:
      - ../dags:/opt/airflow/dags
      - ../logs:/opt/airflow/logs
      - ../spark-scripts:/spark-scripts
      - ../data:/data
      - ../scripts:/scripts
      - ${HOME}/.GCP:/root/.GCP
      - ${HOME}/.AWS:/root/.AWS

services:
  airflow-scheduler:
    <<: *airflow-common
    container_name: ${AIRFLOW_SCHEDULER_CONTAINER_NAME}
    hostname: ${AIRFLOW_SCHEDULER_CONTAINER_NAME}
    command: scheduler
    restart: on-failure
    environment:
      <<: *airflow-common-env

  airflow-webserver:
    <<: *airflow-common
    container_name: ${AIRFLOW_WEBSERVER_CONTAINER_NAME}
    hostname: ${AIRFLOW_WEBSERVER_CONTAINER_NAME}
    entrypoint: /scripts/entrypoint.sh
    command: webserver
    restart: always
    depends_on:
    - airflow-scheduler
    environment:
      <<: *airflow-common-env
    ports:
      - ${AIRFLOW_WEBSERVER_PORT}:8080

networks:
 default:
  name: Batching-Processing
  external: true